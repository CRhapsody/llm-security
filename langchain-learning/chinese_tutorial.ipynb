{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "os.environ[\"http_proxy\"]=\"127.0.0.1:10809\"\n",
    "os.environ[\"https_proxy\"]=\"127.0.0.1:10809\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "os.environ[\"SERPAPI_API_KEY\"] = '2492ece101dac805dcdd14e41ac9fd5d0e23ee121efb712d840679a367ed36c4'\n",
    "\n",
    "llm = OpenAI(max_tokens=2048,temperature=0)\n",
    "# llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",max_tokens=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n人工智能是一种技术，它可以帮助人们解决复杂的问题，提高工作效率，改善生活质量。它可以帮助我们更好地理解世界，更好地掌握信息，更好地控制机器，更好地控制环境，更好地控制自己。它可以帮助我们更好地利用资源，更好地控制成本，更好地提高生产力，更好地提高效率，更好地提高质量。总之，人工智能是一种非常有用的技术，它可以帮助我们更好地实现自己的目标。'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"怎样评价人工智能\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import Agent\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should look up the current date and then search for historical events that have taken place on that day.\n",
      "Action: Search\n",
      "Action Input: Current date\u001b[0m\u001b[36;1m\u001b[1;3mToday's current date and time with time zone and date picker: Select locale. en-US. Tuesday, April 18, 2023. 5:00:05 PM. PST8PDT (GMT-7).\u001b[0m\u001b[32;1m\u001b[1;3m I should now search for historical events that have taken place on this day.\n",
      "Action: Search\n",
      "Action Input: Historical events April 18\u001b[0m\u001b[36;1m\u001b[1;3mOn this day - April 18\u001b[0m\u001b[32;1m\u001b[1;3m I now know the historical events that have taken place on this day.\n",
      "Final Answer: Today is Tuesday, April 18, 2023. On this day in history, the first successful ascent of Mount Everest was made by Edmund Hillary and Tenzing Norgay in 1953, the first Earth Day was celebrated in 1970, and the first successful flight of the Wright Flyer was made in 1903.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Today is Tuesday, April 18, 2023. On this day in history, the first successful ascent of Mount Everest was made by Edmund Hillary and Tenzing Norgay in 1953, the first Earth Day was celebrated in 1970, and the first successful flight of the Wright Flyer was made in 1903.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = load_tools([\"serpapi\"])\n",
    "# 如果搜索完想在计算一下可以这么写\n",
    "# tools = load_tools(['serpapi', 'llm-math'])\n",
    "\n",
    "# 如果搜索完想再让他再用python的print做点简单的计算，可以这样写\n",
    "# tools=load_tools([\"serpapi\",\"python_repl\"])\n",
    "\n",
    "# 工具加载后都需要初始化，verbose 参数为 True，会打印全部的执行详情\n",
    "agent = initialize_agent(tools, llm, AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n",
    "\n",
    "# 运行 agent\n",
    "agent.run(\"What's the date today? What great events have taken place today in history?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对超长文本进行总结\n",
    "假如我们想要用 openai api 对一个段文本进行总结，我们通常的做法就是直接发给 api 让他总结。但是如果文本超过了 api 最大的 token 限制就会报错。\n",
    "\n",
    "这时，我们一般会进行对文章进行分段，比如通过 tiktoken 计算并分割，然后将各段发送给 api 进行总结，最后将各段的总结再进行一个全部的总结。\n",
    "如果，你用是 LangChain，他很好的帮我们处理了这个过程，使得我们编写代码变的非常简单。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入文本\n",
    "loader = UnstructuredFileLoader(\"C:\\\\Users\\\\czmcz\\\\Desktop\\\\研究生文件\\\\工具及实验\\\\llm-security\\\\langchain-learning\\\\sample_data\\\\large_text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents:1\n"
     ]
    }
   ],
   "source": [
    "# 将文本转成 Document 对象\n",
    "document = loader.load()\n",
    "print(f'documents:{len(document)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents:2372\n"
     ]
    }
   ],
   "source": [
    "# 切分文本\n",
    "split_documents = text_splitter.split_documents(document)\n",
    "print(f'documents:{len(split_documents)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 llm 模型\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", max_tokens=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"[{\"question\": \"Were Scott Derrickson and Ed Wood of the same nationality?\", \"answer\": \"yes\", \"type\": \"comparison\"}, {\"question\": \"What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?\", \"answer\": \"Chief of Protocol\", \"type\": \"bridge\"}, {\"question\": \"What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?\", \"answer\": \"Animorphs\", \"type\": \"bridge\"},\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point:  This set of questions covers a range of topics, from comparison (Scott Derrickson and Ed Wood's nationality) to bridge (the actress who portrayed Corliss Archer in Kiss and Tell and the science fantasy young adult series Animorphs). The answers provided are yes, Chief of Protocol, and Animorphs, respectively.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "{\"question\": \"Are the Laleli Mosque and Esma Sultan Mansion located in the same neighborhood?\", \"answer\": \"no\", \"type\": \"comparison\"}, {\"question\": \"The director of the romantic comedy \\\"Big Stone Gap\\\" is based in what New York city?\", \"answer\": \"Greenwich Village, New York City\", \"type\": \"bridge\"}, {\"question\": \"2014 S/S is the debut album of a South Korean boy group that was formed by who?\", \"answer\": \"YG Entertainment\", \"type\": \"bridge\"}, {\"question\": \"Who was known by his stage name Aladin\n",
      "------------\n",
      "Given the new context, refine the original summaryIf the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "\n",
      "This set of questions covers a range of topics, from comparison (the Laleli Mosque and Esma Sultan Mansion) to bridge (the director of the romantic comedy \"Big Stone Gap\", 2014 S/S debut album of a South Korean boy group, and the stage name Aladin). The answers provided are no, Greenwich Village, New York City and YG Entertainment, respectively.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "and helped organizations improve their performance as a consultant?\", \"answer\": \"Eenasul Fateh\", \"type\": \"bridge\"}, {\"question\": \"The arena where the Lewiston Maineiacs played their home games can seat how many people?\", \"answer\": \"3,677 seated\", \"type\": \"bridge\"}, {\"question\": \"Who is older, Annie Morton or Terry Richardson?\", \"answer\": \"Terry Richardson\", \"type\": \"bridge\"}, {\"question\": \"Are Local H and For Against both from the United States?\", \"answer\": \"yes\", \"type\": \"comparison\"},\n",
      "------------\n",
      "Given the new context, refine the original summaryIf the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "\n",
      "This set of questions covers a range of topics, from comparison (the Laleli Mosque and Esma Sultan Mansion, Local H and For Against) to bridge (the director of the romantic comedy \"Big Stone Gap\", 2014 S/S debut album of a South Korean boy group, the stage name Aladin, Eenasul Fateh, the Lewiston Maineiacs' home arena and Terry Richardson's age). The answers provided are no, Greenwich Village, New York City, YG Entertainment, 3,677 seated, yes and Terry Richardson, respectively.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "{\"question\": \"What is the name of the fight song of the university whose main campus is in Lawrence, Kansas and whose branch campuses are in the Kansas City metropolitan area?\", \"answer\": \"Kansas Song\", \"type\": \"bridge\"}, {\"question\": \"What screenwriter with credits for \\\"Evolution\\\" co-wrote a film starring Nicolas Cage and T\\u00e9a Leoni?\", \"answer\": \"David Weissman\", \"type\": \"bridge\"}, {\"question\": \"What year did Guns N Roses perform a promo for a movie starring Arnold Schwarzenegger as a\n",
      "------------\n",
      "Given the new context, refine the original summaryIf the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point: \n",
      "This set of questions covers a range of topics, from comparison (the Laleli Mosque and Esma Sultan Mansion, Local H and For Against) to bridge (the director of the romantic comedy \"Big Stone Gap\", 2014 S/S debut album of a South Korean boy group, the stage name Aladin, Eenasul Fateh, the Lewiston Maineiacs' home arena, the fight song of the university whose main campus is in Lawrence, Kansas and whose branch campuses are in the Kansas City metropolitan area, screenwriter with credits for \"Evolution\" co-wrote a film starring Nicolas Cage and Téa Leoni, and Guns N' Roses' promo performance for a movie starring Arnold Schwarzenegger). The answers provided are no, Greenwich Village, New York City, YG Entertainment, 3,677 seated, yes, Kansas Song, David Weissman and the year of performance respectively.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "former New York Police detective?\", \"answer\": \"1999\", \"type\": \"bridge\"}, {\"question\": \"Are Random House Tower and 888 7th Avenue both used for real estate?\", \"answer\": \"no\", \"type\": \"comparison\"}, {\"question\": \"The football manager who recruited David Beckham managed Manchester United during what timeframe?\", \"answer\": \"from 1986 to 2013\", \"type\": \"bridge\"}, {\"question\": \"Brown State Fishing Lake is in a country that has a population of how many inhabitants ?\", \"answer\": \"9,984\", \"type\":\n",
      "------------\n",
      "Given the new context, refine the original summaryIf the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThis set of questions covers a range of topics, from comparison (the Laleli Mosque and Esma Sultan Mansion, Local H and For Against, Random House Tower and 888 7th Avenue) to bridge (the director of the romantic comedy \"Big Stone Gap\", 2014 S/S debut album of a South Korean boy group, the stage name Aladin, Eenasul Fateh, the Lewiston Maineiacs\\' home arena, the fight song of the university whose main campus is in Lawrence, Kansas and whose branch campuses are in the Kansas City metropolitan area, screenwriter with credits for \"Evolution\" co-wrote a film starring Nicolas Cage and Téa Leoni, former New York Police detective, football manager who recruited David Beckham, Brown State Fishing Lake). The answers provided are no, Greenwich Village, New York City, YG Entertainment, 3,677 seated, yes, Kansas Song, David Weissman, 1999, from 1986 to 2013, and 9,984 respectively.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建总结链\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\", verbose=True)\n",
    "\n",
    "# 执行总结链，（为了快速演示，只总结前5段）\n",
    "chain.run(split_documents[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建本地知识库问答机器人\n",
    "在这个例子中，我们会介绍如何从我们本地读取多个文档构建知识库，并且使用 Openai API 在知识库中进行搜索并给出答案。\n",
    "这个是个很有用的教程，比如可以很方便的做一个可以介绍公司业务的机器人，或是介绍一个产品的机器人。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n",
      "c:\\softwares\\Miniconda3\\envs\\llm-security\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:185: UserWarning: `VectorDBQA` is deprecated - please use `from langchain.chains import RetrievalQA`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NotEnoughElementsException",
     "evalue": "Number of requested results 4 cannot be greater than number of elements in index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotEnoughElementsException\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m qa \u001b[39m=\u001b[39m VectorDBQA\u001b[39m.\u001b[39mfrom_chain_type(llm\u001b[39m=\u001b[39mOpenAI(), chain_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstuff\u001b[39m\u001b[39m\"\u001b[39m, vectorstore\u001b[39m=\u001b[39mdocsearch,return_source_documents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m \u001b[39m# 进行问答\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m result \u001b[39m=\u001b[39m qa({\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m科大讯飞今年第一季度收入是多少？\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n\u001b[0;32m     27\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[1;32mc:\\softwares\\Miniconda3\\envs\\llm-security\\lib\\site-packages\\langchain\\chains\\base.py:117\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[1;32mc:\\softwares\\Miniconda3\\envs\\llm-security\\lib\\site-packages\\langchain\\chains\\base.py:114\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    109\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[0;32m    110\u001b[0m     inputs,\n\u001b[0;32m    111\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    113\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[0;32m    115\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\softwares\\Miniconda3\\envs\\llm-security\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:109\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run get_relevant_text and llm on input query.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m \u001b[39mIf chain has 'return_source_documents' as 'True', returns\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39manswer, docs = res['result'], res['source_documents']\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m question \u001b[39m=\u001b[39m inputs[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key]\n\u001b[1;32m--> 109\u001b[0m docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_docs(question)\n\u001b[0;32m    110\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine_documents_chain\u001b[39m.\u001b[39mrun(\n\u001b[0;32m    111\u001b[0m     input_documents\u001b[39m=\u001b[39mdocs, question\u001b[39m=\u001b[39mquestion\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_source_documents:\n",
      "File \u001b[1;32mc:\\softwares\\Miniconda3\\envs\\llm-security\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py:202\u001b[0m, in \u001b[0;36mVectorDBQA._get_docs\u001b[1;34m(self, question)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_docs\u001b[39m(\u001b[39mself\u001b[39m, question: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[0;32m    201\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msimilarity\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 202\u001b[0m         docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectorstore\u001b[39m.\u001b[39;49msimilarity_search(\n\u001b[0;32m    203\u001b[0m             question, k\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearch_kwargs\n\u001b[0;32m    204\u001b[0m         )\n\u001b[0;32m    205\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmmr\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    206\u001b[0m         docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectorstore\u001b[39m.\u001b[39mmax_marginal_relevance_search(\n\u001b[0;32m    207\u001b[0m             question, k\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_kwargs\n\u001b[0;32m    208\u001b[0m         )\n",
      "File \u001b[1;32mc:\\softwares\\Miniconda3\\envs\\llm-security\\lib\\site-packages\\langchain\\vectorstores\\chroma.py:144\u001b[0m, in \u001b[0;36mChroma.similarity_search\u001b[1;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimilarity_search\u001b[39m(\n\u001b[0;32m    128\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    129\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    133\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[0;32m    134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run similarity search with Chroma.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \n\u001b[0;32m    136\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39m        List[Document]: List of documents most similar to the query text.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     docs_and_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msimilarity_search_with_score(query, k, \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m)\n\u001b[0;32m    145\u001b[0m     \u001b[39mreturn\u001b[39;00m [doc \u001b[39mfor\u001b[39;00m doc, _ \u001b[39min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[1;32mc:\\softwares\\Miniconda3\\envs\\llm-security\\lib\\site-packages\\langchain\\vectorstores\\chroma.py:190\u001b[0m, in \u001b[0;36mChroma.similarity_search_with_score\u001b[1;34m(self, query, k, filter, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     query_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function\u001b[39m.\u001b[39membed_query(query)\n\u001b[1;32m--> 190\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collection\u001b[39m.\u001b[39;49mquery(\n\u001b[0;32m    191\u001b[0m         query_embeddings\u001b[39m=\u001b[39;49m[query_embedding], n_results\u001b[39m=\u001b[39;49mk, where\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m\n\u001b[0;32m    192\u001b[0m     )\n\u001b[0;32m    194\u001b[0m \u001b[39mreturn\u001b[39;00m _results_to_docs_and_scores(results)\n",
      "File \u001b[1;32mc:\\softwares\\Miniconda3\\envs\\llm-security\\lib\\site-packages\\chromadb\\api\\models\\Collection.py:202\u001b[0m, in \u001b[0;36mCollection.query\u001b[1;34m(self, query_embeddings, query_texts, n_results, where, where_document, include)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39mif\u001b[39;00m where_document \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     where_document \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_query(\n\u001b[0;32m    203\u001b[0m     collection_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    204\u001b[0m     query_embeddings\u001b[39m=\u001b[39;49mquery_embeddings,\n\u001b[0;32m    205\u001b[0m     n_results\u001b[39m=\u001b[39;49mn_results,\n\u001b[0;32m    206\u001b[0m     where\u001b[39m=\u001b[39;49mwhere,\n\u001b[0;32m    207\u001b[0m     where_document\u001b[39m=\u001b[39;49mwhere_document,\n\u001b[0;32m    208\u001b[0m     include\u001b[39m=\u001b[39;49minclude,\n\u001b[0;32m    209\u001b[0m )\n",
      "File \u001b[1;32mc:\\softwares\\Miniconda3\\envs\\llm-security\\lib\\site-packages\\chromadb\\api\\local.py:247\u001b[0m, in \u001b[0;36mLocalAPI._query\u001b[1;34m(self, collection_name, query_embeddings, n_results, where, where_document, include)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_query\u001b[39m(\n\u001b[0;32m    239\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    240\u001b[0m     collection_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    245\u001b[0m     include: Include \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mdocuments\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmetadatas\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdistances\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     uuids, distances \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_db\u001b[39m.\u001b[39;49mget_nearest_neighbors(\n\u001b[0;32m    248\u001b[0m         collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[0;32m    249\u001b[0m         where\u001b[39m=\u001b[39;49mwhere,\n\u001b[0;32m    250\u001b[0m         where_document\u001b[39m=\u001b[39;49mwhere_document,\n\u001b[0;32m    251\u001b[0m         embeddings\u001b[39m=\u001b[39;49mquery_embeddings,\n\u001b[0;32m    252\u001b[0m         n_results\u001b[39m=\u001b[39;49mn_results,\n\u001b[0;32m    253\u001b[0m     )\n\u001b[0;32m    255\u001b[0m     include_embeddings \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m include\n\u001b[0;32m    256\u001b[0m     include_documents \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdocuments\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m include\n",
      "File \u001b[1;32mc:\\softwares\\Miniconda3\\envs\\llm-security\\lib\\site-packages\\chromadb\\db\\clickhouse.py:520\u001b[0m, in \u001b[0;36mClickhouse.get_nearest_neighbors\u001b[1;34m(self, where, where_document, embeddings, n_results, collection_name, collection_uuid)\u001b[0m\n\u001b[0;32m    517\u001b[0m     ids \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    519\u001b[0m index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index(collection_uuid)\n\u001b[1;32m--> 520\u001b[0m uuids, distances \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_nearest_neighbors(embeddings, n_results, ids)\n\u001b[0;32m    522\u001b[0m \u001b[39mreturn\u001b[39;00m uuids, distances\n",
      "File \u001b[1;32mc:\\softwares\\Miniconda3\\envs\\llm-security\\lib\\site-packages\\chromadb\\db\\index\\hnswlib.py:229\u001b[0m, in \u001b[0;36mHnswlib.get_nearest_neighbors\u001b[1;34m(self, query, k, ids)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_dimensionality(query)\n\u001b[0;32m    228\u001b[0m \u001b[39mif\u001b[39;00m k \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_metadata[\u001b[39m\"\u001b[39m\u001b[39melements\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m--> 229\u001b[0m     \u001b[39mraise\u001b[39;00m NotEnoughElementsException(\n\u001b[0;32m    230\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of requested results \u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m cannot be greater than number of elements in index \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_metadata[\u001b[39m'\u001b[39m\u001b[39melements\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m     )\n\u001b[0;32m    233\u001b[0m s2 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    234\u001b[0m \u001b[39m# get ids from uuids as a set, if they are available\u001b[39;00m\n",
      "\u001b[1;31mNotEnoughElementsException\u001b[0m: Number of requested results 4 cannot be greater than number of elements in index 1"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import OpenAI,VectorDBQA\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# 加载文件夹中的所有txt类型的文件\n",
    "loader = DirectoryLoader(\"C:\\\\Users\\\\czmcz\\\\Desktop\\\\研究生文件\\\\工具及实验\\\\llm-security\\\\langchain-learning\\\\sample_data\\\\\", glob='**/*.txt')\n",
    "# 将数据转成 document 对象，每个文件会作为一个 document\n",
    "documents = loader.load()\n",
    "\n",
    "# 初始化加载器\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "# 切割加载的 document\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 初始化 openai 的 embeddings 对象\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# 将 document 通过 openai 的 embeddings 对象计算 embedding 向量信息并临时存入 Chroma 向量数据库，用于后续匹配查询\n",
    "docsearch = Chroma.from_documents(split_docs, embeddings)\n",
    "\n",
    "# 创建问答对象\n",
    "qa = VectorDBQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", vectorstore=docsearch,return_source_documents=True)\n",
    "# 进行问答\n",
    "result = qa({\"query\": \"科大讯飞今年第一季度收入是多少？\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: C:/vector_store\n",
      "Using embedded DuckDB with persistence: data will be stored in: C:/vector_store\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# 持久化数据\n",
    "docsearch = Chroma.from_documents(documents, embeddings, persist_directory=\"C:/vector_store\")\n",
    "docsearch.persist()\n",
    "\n",
    "# 加载数据\n",
    "docsearch = Chroma(persist_directory=\"C:/vector_store\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "这个视频展示了Unreal Engine 5.2的一些新实验性功能，包括支持植被渲染的新功能、与Rivian合作展示R1T电动皮卡的实时渲染、新的材质框架Substrate以及全新的程序化内容生成工具。视频中展示了这些功能的效果，并介绍了它们的应用场景和优势。\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Unreal Engine 5.2增加了支持植被渲染的新功能、与Rivian合作展示R1T电动皮卡的实时渲染、新的材质框架Substrate以及全新的程序化内容生成工具。这些功能的效果在视频中展示，并介绍了它们的应用场景和优势。此外，Unreal Engine 5.2还支持混合现实、虚拟现实和增强现实应用程序的开发。\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ChatVectorDBChain, ConversationalRetrievalChain\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "  ChatPromptTemplate,\n",
    "  SystemMessagePromptTemplate,\n",
    "  HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "# 加载 youtube 频道\n",
    "loader = YoutubeLoader.from_youtube_url('https://www.youtube.com/watch?v=Dj60HHy-Kqk')\n",
    "# 将数据转成 document\n",
    "documents = loader.load()\n",
    "\n",
    "# 初始化文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1000,\n",
    "  chunk_overlap=20\n",
    ")\n",
    "\n",
    "# 分割 youtube documents\n",
    "documents = text_splitter.split_documents(documents)\n",
    "\n",
    "# 初始化 openai embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# 将数据存入向量存储\n",
    "vector_store = Chroma.from_documents(documents, embeddings)\n",
    "# 通过向量存储初始化检索器\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "system_template = \"\"\"\n",
    "Use the following context to answer the user's question.\n",
    "If you don't know the answer, say you don't, don't try to make it up. And answer in Chinese.\n",
    "-----------\n",
    "{context}\n",
    "-----------\n",
    "{chat_history}\n",
    "\"\"\"\n",
    "\n",
    "# 构建初始 messages 列表，这里可以理解为是 openai 传入的 messages 参数\n",
    "messages = [\n",
    "  SystemMessagePromptTemplate.from_template(system_template),\n",
    "  HumanMessagePromptTemplate.from_template('{question}')\n",
    "]\n",
    "\n",
    "# 初始化 prompt 对象\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "\n",
    "# 初始化问答链\n",
    "qa = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0.1,max_tokens=2048),retriever,qa_prompt=prompt,verbose=True)\n",
    "\n",
    "\n",
    "chat_history = []\n",
    "while True:\n",
    "  question = input('问题：')\n",
    "  # 开始发送问题 chat_history 为必须参数,用于存储对话历史\n",
    "  result = qa({'question': question, 'chat_history': chat_history})\n",
    "  chat_history.append((question, result['answer']))\n",
    "  print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatOpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m CallbackManager\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstreaming_stdout\u001b[39;00m \u001b[39mimport\u001b[39;00m StreamingStdOutCallbackHandler\n\u001b[1;32m----> 4\u001b[0m chat \u001b[39m=\u001b[39m ChatOpenAI(streaming\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, callback_manager\u001b[39m=\u001b[39mCallbackManager([StreamingStdOutCallbackHandler()]), verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, temperature\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m resp \u001b[39m=\u001b[39m chat(chat_prompt_with_values\u001b[39m.\u001b[39mto_messages())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ChatOpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(streaming=True, callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), verbose=True, temperature=0)\n",
    "resp = chat(chat_prompt_with_values.to_messages())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-security",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
